Using AI to Create Knitting Patterns

[Languages and packages used: R - ravelRy libaray, Python - GPT-2 package]

This project began with the idea to combine two seemingly disparate things, machine learning and knitting.  There has been a recent trend on TikTok of crocheting patterns created by ChatGPT. This spawned the idea of using a text generation AI model to create knitting patterns. All text AI models need data for training. This new pattern generating model would need the text of hundreds of knitting patterns for training. There is a large repository of knitting patterns on the website Ravelry.com. There are currently over 700,000 knitting patterns on Ravelry. In order to ensure better results from the AI model, the type of knitting pattern was restricted to hats for adults. 

The data for this project ended up consisting of 357 hat knitting patterns. The process of collecting this data began with using ravelRy, an R library for accessing the Ravelry.com API. The library ravelRy facilitates searches of patterns from Ravelry. Each search returns a list of pattern id numbers. The id numbers identify a pattern, which each have attributes like name, whether or not the pattern is free, whether or not it is downloadable, and a url to the pdf. After retrieving 5000 pattern ids, all with the search query “hat” and availability of “free,” 593 had a non-empty field for the pdf url. 

These pdf urls were then exported to a .csv file. All further data manipulation was done in python. The next step was to download all the pdfs using the urls. However, some of the urls no longer led to a pdf. From 593 links, 357 pdfs had valid download links. The text generation AI model needed all the input text to be in a single .txt file. So, the pdfs were next converted into text and added to a single text file. 

Two different methods of generating AI knitting patterns were used for this project. First was the python package GPT-2 from OpenAI and the second method was ChatGPT.

Most knitting patterns are usually broken up into sections. First is a list of materials, which details how much, and what kind of yarn to use. Then is a section on gauge, which specifies how tightly to knit the hat to get the correct size in the end. Gauge is important to ensure consistency in a craft that is handmade and has variation. Next is a section on the types of stitches that will be used in the pattern, this section is sometimes combined with the section on the abbreviations used. Next comes the body of the pattern, for hats this is sometimes broken up into subsections on the brim, body, and crown. The body of the pattern is made up of numbered rows or rounds. Finally is a section on how to finish the hat, and an optional section on how to make a pompom to attach to the top of the hat. Other things some patterns have are stitch charts and pictures. Both charts and pictures were removed from the patterns when they were converted to text, but the text would still refer to them.

The generated knitting patterns from each model were next evaluated for accuracy and ease-of-use. GPT-2 produced two patterns, one after 300 training steps and one after 400 steps. Both patterns are clearly knitting patterns, but neither one could be used to actually knit a hat. Each has some of the sections necessary to create a hat pattern, but neither has all the sections. Both the pattern produced after 300 steps and the one produced after 400 steps look like random lines from several knitting patterns were cut and pasted together. They are clearly created by an AI. 

The ChatGPT pattern, on the other hand, is entirely usable as a knitting pattern. It contains several sections, one on materials, a section on gauge, and the main body of the pattern says how to make the hat, including the decreases for the hat crown. Even a novice knitter could use this pattern to make a simple knit hat. If given to a knitter, it may not be apparent to them that this pattern was generated by AI.

There is a lot of future work that could be done on this project. The change that would make the most difference would be to allow the GPT-2 model to train for more steps. After 1000, or even 5000 steps GPT-2 may be able to create a usable hat knitting pattern. Another change that could be made is to the data. Using both more patterns and less edited data could produce a better pattern. By editing out parts of the original pdf text it may have impacted the resultant AI generated pattern. Alternatively, more editing could be done to remove all parts of the patterns except the main pattern body. With more constrained data the AI models might be able to produce a more coherent result. Finally, different methods from GPT-2 could be used, or the same finetune method with different parameters. By trying different parameters the combination that produces the best pattern could be found.

